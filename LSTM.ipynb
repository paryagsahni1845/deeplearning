{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paryagsahni1845/deeplearning/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "SH4CDpAvTGHJ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyRXNqGzYZwa",
        "outputId": "73215cb1-321e-4dd7-ba66-636de84b130d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O79ddXE84Xi",
        "outputId": "6d27e5a4-1796-4636-9e1d-9ae0c3459fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"imdb\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<br />\", \" \", text)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "    return text.split()\n",
        "\n",
        "# Build vocab from training data (top 30k words)\n",
        "all_tokens = []\n",
        "for sample in dataset['train']:\n",
        "    all_tokens.extend(tokenize(sample['text']))\n",
        "\n",
        "vocab_count = Counter(all_tokens)\n",
        "vocab = {word: idx+1 for idx, (word, _) in enumerate(vocab_count.most_common(30000))}\n",
        "vocab['<PAD>'] = 0\n",
        "vocab_size = len(vocab)\n"
      ],
      "metadata": {
        "id": "kgBC9RpAPXRw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IMDBDataset(Dataset): # Inherit from torch.utils.data.Dataset\n",
        "    def __init__(self, data, vocab):\n",
        "        self.texts = [tokenize(s['text']) for s in data]\n",
        "        self.labels = [s['label'] for s in data]\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.texts[idx]\n",
        "        seq = [self.vocab.get(token, 0) for token in tokens]\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(seq, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch: list of (seq, label)\n",
        "    sequences, labels = zip(*batch)\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
        "    padded_seqs = nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    labels = torch.stack(labels)\n",
        "    return padded_seqs, labels, lengths"
      ],
      "metadata": {
        "id": "aKrOqIV9PhC5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = IMDBDataset(dataset['train'], vocab)\n",
        "test_dataset = IMDBDataset(dataset['test'], vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "e8FeckxiPl7G"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=200, hidden_dim=256, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = self.embedding(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, (h_n, _) = self.lstm(packed)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "model = LSTMClassifier(vocab_size=vocab_size).to(device)\n"
      ],
      "metadata": {
        "id": "05rPtIW4PsgZ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):  # train longer\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb, lengths in train_loader:\n",
        "        xb, yb, lengths = xb.to(device), yb.to(device), lengths.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb, lengths)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrbGumbYPwiU",
        "outputId": "c0c1a411-0695-442c-b647-1bbb1cc48b90"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6191\n",
            "Epoch 2, Loss: 0.4983\n",
            "Epoch 3, Loss: 0.2753\n",
            "Epoch 4, Loss: 0.1614\n",
            "Epoch 5, Loss: 0.0787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for xb, yb, lengths in test_loader:\n",
        "        xb, yb, lengths = xb.to(device), yb.to(device), lengths.to(device)\n",
        "        outputs = model(xb, lengths)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += yb.size(0)\n",
        "        correct += (predicted == yb).sum().item()\n",
        "\n",
        "print(\"Test Accuracy:\", correct / total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJR1NIvRP0Kr",
        "outputId": "36a59b6d-d9fd-4f32-f71d-2c049887b6ed"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.87772\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPF3k26gYJr71csoeegqNvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}