{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65859e51",
   "metadata": {},
   "source": [
    "The sigmoid function maps any real-valued input to a value between 0 and 1, making it useful for binary classification in neural networks.\n",
    "Apply it at the output layer when the target is 0 or 1, to interpret output as probability.\n",
    "It’s used in problems like disease prediction, spam detection, etc.\n",
    "Avoid it in hidden layers, as it causes vanishing gradients and slows learning.\n",
    "Use ReLU or tanh in hidden layers instead for better gradient flow and training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2290abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ceece",
   "metadata": {},
   "source": [
    "The Breast Cancer Wisconsin dataset contains features computed from breast mass cell images to classify tumors as benign (0) or malignant (1).\n",
    "It has 569 samples with 30 numerical features like radius, texture, smoothness, etc.\n",
    "It’s commonly used for binary classification tasks to evaluate models like logistic regression and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20660482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6044060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 16)  # Input layer to hidden layer\n",
    "        self.fc2 = nn.Linear(16, 1)                  # Hidden layer to output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))  # Sigmoid activation\n",
    "        x = self.fc2(x)                  # Output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7b2db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.BCEWithLogitsLoss()  # Loss function for binary classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "722f64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    model.train()                      # Set model to training mode\n",
    "    optimizer.zero_grad()              # Clear gradients\n",
    "    outputs = model(X_train_tensor)    # Forward pass\n",
    "    loss = criterion(outputs, y_train_tensor)  # Compute loss\n",
    "    loss.backward()                    # Backpropagation\n",
    "    optimizer.step()                   # Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1e31bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 0.])\n",
      "Accuracy: 0.9561403393745422\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predicted = torch.sigmoid(test_outputs)  # Apply sigmoid to get probabilities\n",
    "    predicted_classes = (predicted > 0.5).float()  # Apply threshold\n",
    "    accuracy = (predicted_classes.view(-1) == torch.tensor(y_test, dtype=torch.float32)).float().mean()  # Calculate accuracy\n",
    "    print(\"Predicted classes:\", predicted_classes.flatten())\n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
